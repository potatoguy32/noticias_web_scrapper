{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3.10.13\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import concurrent.futures\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "\n",
    "from retry import retry\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "import selenium_scrappers as scrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definición de parámetros para la extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listado de palabras a poner en la barra de busqueda\n",
    "grupos = ['mineria ilegal']\n",
    "\n",
    "# Criterios a buscar en cada noticia que aparezca en la busqueda\n",
    "criterios = [' oro ', 'minería ilegal', 'minería clandestina']\n",
    "\n",
    "carteles = ['CJNG', 'cartel de jalisco nueva generacion', 'cártel de jalisco nueva generación',\n",
    "            'CDS', 'Cartel de sinaloa', 'cártel de sinaloa','CDG', 'cartel del golfo',\n",
    "            'cártel del golfo','CDN', 'cartel del noreste', 'cártel del noreste','NFM',\n",
    "            'nueva familia michoacana']\n",
    "\n",
    "actividades = ['robo', 'extorsión', 'homicidio']\n",
    "\n",
    "# Nombres de los archivos que guarda el scrapper\n",
    "nombre = 'prueba_scrapper_1'\n",
    "nombre_archivo_extraccion = f'{nombre}_raw' # file con titulo y link de cada noticia encontrada\n",
    "nombre_archivo_filtrado = f'{nombre}_filtrado' # file con las noticias que cumplen los criterios \n",
    "nombre_indice = f'{nombre}_indice' # 2 indices son creados, uno expandido con el parrafo especifico donde se encontro el match y uno resumido listando los matches en cada noticia\n",
    "\n",
    "municipios = pd.read_excel('extraction_files/municipios.xlsx', usecols=['ESTADO', 'MUNICIPIO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso de extracción de links\n",
    "# Este proceso no es necesario en caso de backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    browser = webdriver.Chrome(ChromeDriverManager().install())\n",
    "except:\n",
    "    browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_entries = {}\n",
    "# extracted_entries = scrappers.extract_links_from_infobae(browser=browser, grupos=grupos)\n",
    "extracted_entries = scrappers.extract_links_from_universal(browser=browser, grupos=grupos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar archivo con todos los links extraídos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'extraction_files/{nombre_archivo_extraccion}.json', 'w') as f:\n",
    "    json.dump(extracted_entries, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opcional: Cargar un archivo con links anteriormente guardado [cambiar nombre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'extraction_files/{nombre_archivo_extraccion}.json', 'r') as f:\n",
    "#     extracted_entries = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de busqueda de criterios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para matar el proceso sin perder las variables seleccionar interrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_entries = {grupo: [('titulo', 'year', 'matching_criterios', 'matching_estados', 'matching_municipios', carteles, actividades, 'url'), ] for grupo in extracted_entries.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for grupo, entries in extracted_entries.items():\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        future_to_url = {executor.submit(utils.get_matches, collector=filtered_entries,\n",
    "                                         grupo=grupo, url=entry, criterios=criterios,\n",
    "                                         municipios=municipios, actividades=actividades,\n",
    "                                         carteles=carteles): entry\n",
    "                         for entry in entries}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar el archivo con las coincidencias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'extraction_files/{nombre_archivo_filtrado}.json', 'w') as f:\n",
    "    json.dump(filtered_entries, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opcional: Leer un archivo filtrado anteriormente guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'extraction_files/{nombre_archivo_filtrado}.json', 'r') as f:\n",
    "#     filtered_entries = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar excel con el formato deseado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "for k, v in filtered_entries.items():\n",
    "    current_df = pd.DataFrame(data=v, columns=('titulo', 'year', 'matching_criterios',\n",
    "                                               'matching_estados', 'matching_municipios',\n",
    "                                               'matching_carteles', 'matching_actividades', 'url'\n",
    "                                               ))\n",
    "    current_df.insert(0, \"busqueda\", k)\n",
    "    datasets.append(current_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df = pd.concat(datasets, ignore_index=True)\n",
    "index_df.drop_duplicates(subset=['url'], inplace=True)\n",
    "index_df = index_df[index_df['titulo'] != 'titulo']\n",
    "index_df[carteles] = index_df['matching_carteles'].to_list()\n",
    "index_df[carteles] = index_df[carteles].astype(int)\n",
    "index_df[actividades] = index_df['matching_actividades'].to_list()\n",
    "index_df[actividades] = index_df[actividades].astype(int)\n",
    "index_df.drop(columns=['matching_carteles', 'matching_actividades'], inplace=True)\n",
    "index_df = index_df[['titulo', 'year', 'matching_criterios', 'matching_estados', 'matching_municipios'] + carteles + actividades + ['url', ]]\n",
    "index_df.to_excel(f\"extraction_files/{nombre_indice}.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
